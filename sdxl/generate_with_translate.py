"""
AnimagineXLå›¾åƒç”Ÿæˆï¼ˆæ”¯æŒKimiç¿»è¯‘ï¼‰
"""
import torch
from diffusers import StableDiffusionXLPipeline
import time
from pathlib import Path
import re
import os

print("=" * 70)
print("AnimagineXL å›¾åƒç”Ÿæˆï¼ˆæ”¯æŒä¸­æ–‡ç¿»è¯‘ï¼‰")
print("=" * 70)

# å¯¼å…¥ç¿»è¯‘æ¨¡å—
from translate_kimi import translate_with_kimi, simple_translate

# æ£€æŸ¥GPU
print("\n[1/5] æ£€æŸ¥ç¯å¢ƒ...")
print(f"âœ“ GPU: {torch.cuda.get_device_name(0)}")
print(f"âœ“ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# æ£€æŸ¥Kimi API
kimi_key = os.environ.get('KIMI_API_KEY')
if kimi_key:
    print("âœ“ Kimi APIå·²é…ç½®")
else:
    print("âš  Kimi APIæœªé…ç½®ï¼Œä½¿ç”¨ç®€å•ç¿»è¯‘")
    print("  è®¾ç½®æ–¹æ³•: set KIMI_API_KEY=your_key")

# åŠ è½½æ¨¡å‹
print("\n[2/5] åŠ è½½æ¨¡å‹...")
model_path = str(Path(__file__).parent / "models" / "animagine-xl-4.0")

pipe = StableDiffusionXLPipeline.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    use_safetensors=True
).to("cuda")

print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")

# å¯ç”¨ä¼˜åŒ–
print("\n[3/5] å¯ç”¨ä¼˜åŒ–...")
pipe.enable_attention_slicing()
pipe.enable_vae_slicing()
print("âœ“ ä¼˜åŒ–å·²å¯ç”¨")

# ä¸­æ–‡æ£€æµ‹
def has_chinese(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

# ç¿»è¯‘å‡½æ•°
def translate_prompt(prompt):
    if not has_chinese(prompt):
        return prompt
    
    if kimi_key:
        return translate_with_kimi(prompt, kimi_key)
    else:
        translated = simple_translate(prompt)
        print(f"  [ç®€å•ç¿»è¯‘] {prompt} -> {translated}")
        return translated

# ç”Ÿæˆå‡½æ•°
def generate_image(prompt_cn, output_name, steps=28):
    print(f"\nåŸå§‹æç¤ºè¯: {prompt_cn}")
    
    # ç¿»è¯‘
    prompt_en = translate_prompt(prompt_cn)
    print(f"è‹±æ–‡æç¤ºè¯: {prompt_en}")
    
    print(f"\nåˆ†è¾¨ç‡: 1024x1024")
    print(f"æ¨ç†æ­¥æ•°: {steps}")
    print("æ­£åœ¨ç”Ÿæˆ...")
    
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    start_time = time.time()
    
    image = pipe(
        prompt=prompt_en,
        negative_prompt="low quality, blurry, distorted, bad anatomy",
        num_inference_steps=steps,
        guidance_scale=7.0,
        height=1024,
        width=1024
    ).images[0]
    
    elapsed = time.time() - start_time
    memory = torch.cuda.max_memory_allocated() / 1024**3
    
    # ä¿å­˜
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    output_path = output_dir / output_name
    image.save(output_path)
    
    print(f"\nâœ“ ç”Ÿæˆå®Œæˆï¼")
    print(f"  ç”Ÿæˆæ—¶é—´: {elapsed:.2f} ç§’")
    print(f"  æ˜¾å­˜å ç”¨: {memory:.2f} GB")
    print(f"  ä¿å­˜ä½ç½®: {output_path.absolute()}")
    
    return elapsed, memory

# æµ‹è¯•ç”Ÿæˆ
print("\n[4/5] ç”Ÿæˆæµ‹è¯•å›¾åƒ...")
print("-" * 70)

test_prompts = [
    ("ä¸€ä¸ªç©¿è“è‰²é•¿è¢çš„è€é“å£«ï¼Œç¥ç§˜çš„å¾®ç¬‘ï¼Œä¸­å›½é£ï¼Œé«˜è´¨é‡ï¼Œç»†èŠ‚ä¸°å¯Œ", "test_è€é“å£«.png"),
    ("ç°ä»£éƒ½å¸‚è¡—é“ï¼Œé»„æ˜æ—¶åˆ†ï¼Œæ¸©æš–çš„å…‰çº¿ï¼Œç”µå½±æ„Ÿï¼Œé«˜è´¨é‡", "test_éƒ½å¸‚.png"),
]

times = []
for i, (prompt, filename) in enumerate(test_prompts, 1):
    print(f"\næµ‹è¯• {i}/{len(test_prompts)}")
    print("-" * 70)
    elapsed, memory = generate_image(prompt, filename)
    times.append(elapsed)

# æ€»ç»“
print("\n[5/5] æµ‹è¯•å®Œæˆï¼")
print("=" * 70)
print(f"\nå¹³å‡é€Ÿåº¦: {sum(times) / len(times):.2f} ç§’/å¼ ")
print(f"æ˜¾å­˜å ç”¨: {memory:.2f} GB")

avg_time = sum(times) / len(times)
if avg_time < 15:
    print("\nğŸš€ é€Ÿåº¦ä¼˜ç§€ï¼å®Œå…¨æ»¡è¶³æ‰¹é‡ç”Ÿæˆéœ€æ±‚")
elif avg_time < 30:
    print("\nâœ“ é€Ÿåº¦è‰¯å¥½ï¼Œå¯ä»¥æ¥å—")
else:
    print("\nâš  é€Ÿåº¦ä¸€èˆ¬")

print("\nä½¿ç”¨è¯´æ˜:")
print("  1. ç›´æ¥è¾“å…¥ä¸­æ–‡æç¤ºè¯")
print("  2. è‡ªåŠ¨ç¿»è¯‘æˆè‹±æ–‡")
print("  3. é…ç½®Kimi APIè·å¾—æ›´å¥½çš„ç¿»è¯‘æ•ˆæœ")
print("     set KIMI_API_KEY=your_key")

print("\n" + "=" * 70)
