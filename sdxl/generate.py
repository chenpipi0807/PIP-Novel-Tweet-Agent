"""
AnimagineXLå›¾åƒç”Ÿæˆ
æ”¯æŒä¸­æ–‡æç¤ºè¯ï¼ˆè‡ªåŠ¨ç¿»è¯‘ï¼‰
"""
import torch
from diffusers import StableDiffusionXLPipeline
import time
from pathlib import Path
import re

print("=" * 70)
print("AnimagineXL å›¾åƒç”Ÿæˆ")
print("=" * 70)

# æ£€æŸ¥GPU
print("\n[1/4] æ£€æŸ¥ç¯å¢ƒ...")
print(f"âœ“ GPU: {torch.cuda.get_device_name(0)}")
print(f"âœ“ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# åŠ è½½æ¨¡å‹
print("\n[2/4] åŠ è½½æ¨¡å‹...")
model_path = str(Path(__file__).parent / "models" / "animagine-xl-4.0")

pipe = StableDiffusionXLPipeline.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    use_safetensors=True
).to("cuda")

print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")

# å¯ç”¨ä¼˜åŒ–
print("\n[3/4] å¯ç”¨ä¼˜åŒ–...")
pipe.enable_attention_slicing()
pipe.enable_vae_slicing()
print("âœ“ ä¼˜åŒ–å·²å¯ç”¨")

# ä¸­æ–‡æ£€æµ‹
def has_chinese(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

# ç®€å•ç¿»è¯‘ï¼ˆåç»­å¯æ¥å…¥APIï¼‰
def translate_prompt(prompt):
    """
    ç®€å•çš„ä¸­æ–‡åˆ°è‹±æ–‡æ˜ å°„
    åç»­å¯ä»¥æ¥å…¥Kimi API
    """
    if not has_chinese(prompt):
        return prompt
    
    # ç®€å•æ˜ å°„è¡¨
    mappings = {
        "è€é“å£«": "old taoist priest",
        "è“è‰²é•¿è¢": "blue robe",
        "ç¥ç§˜": "mysterious",
        "å¾®ç¬‘": "smile",
        "ä¸­å›½é£": "chinese style",
        "ç°ä»£éƒ½å¸‚": "modern city",
        "è¡—é“": "street",
        "é»„æ˜": "sunset",
        "æ¸©æš–": "warm",
        "å…‰çº¿": "lighting",
        "ç”µå½±æ„Ÿ": "cinematic",
        "é«˜è´¨é‡": "high quality",
        "ç»†èŠ‚": "detailed",
    }
    
    result = prompt
    for cn, en in mappings.items():
        result = result.replace(cn, en)
    
    print(f"  [ç¿»è¯‘] {prompt} -> {result}")
    return result

# ç”Ÿæˆå›¾åƒ
print("\n[4/4] ç”Ÿæˆå›¾åƒ...")
print("-" * 70)

# æµ‹è¯•æç¤ºè¯ï¼ˆä¸­æ–‡ï¼‰
prompt_cn = "ä¸€ä¸ªç©¿è“è‰²é•¿è¢çš„è€é“å£«ï¼Œç¥ç§˜çš„å¾®ç¬‘ï¼Œä¸­å›½é£ï¼Œé«˜è´¨é‡"

print(f"\nåŸå§‹æç¤ºè¯: {prompt_cn}")

# ç¿»è¯‘
prompt_en = translate_prompt(prompt_cn)
print(f"è‹±æ–‡æç¤ºè¯: {prompt_en}")

print("\nåˆ†è¾¨ç‡: 1024x1024")
print("æ¨ç†æ­¥æ•°: 28")
print("\næ­£åœ¨ç”Ÿæˆ...")

torch.cuda.empty_cache()
torch.cuda.reset_peak_memory_stats()

start_time = time.time()

image = pipe(
    prompt=prompt_en,
    negative_prompt="low quality, blurry, distorted",
    num_inference_steps=28,
    guidance_scale=7.0,
    height=1024,
    width=1024
).images[0]

elapsed = time.time() - start_time
memory = torch.cuda.max_memory_allocated() / 1024**3

# ä¿å­˜
output_dir = Path("output")
output_dir.mkdir(exist_ok=True)
output_path = output_dir / "test_è€é“å£«.png"
image.save(output_path)

print(f"\nâœ“ ç”Ÿæˆå®Œæˆï¼")
print(f"  ç”Ÿæˆæ—¶é—´: {elapsed:.2f} ç§’")
print(f"  æ˜¾å­˜å ç”¨: {memory:.2f} GB")
print(f"  ä¿å­˜ä½ç½®: {output_path.absolute()}")

# å†ç”Ÿæˆä¸€å¼ 
print("\n" + "-" * 70)
print("ç”Ÿæˆç¬¬äºŒå¼ ...")

prompt_cn2 = "ç°ä»£éƒ½å¸‚è¡—é“ï¼Œé»„æ˜ï¼Œæ¸©æš–å…‰çº¿ï¼Œç”µå½±æ„Ÿ"
prompt_en2 = translate_prompt(prompt_cn2)

torch.cuda.empty_cache()
start_time = time.time()

image2 = pipe(
    prompt=prompt_en2,
    negative_prompt="low quality, blurry",
    num_inference_steps=28,
    guidance_scale=7.0,
    height=1024,
    width=1024
).images[0]

elapsed2 = time.time() - start_time
output_path2 = output_dir / "test_éƒ½å¸‚.png"
image2.save(output_path2)

print(f"\nâœ“ ç”Ÿæˆå®Œæˆï¼")
print(f"  ç”Ÿæˆæ—¶é—´: {elapsed2:.2f} ç§’")
print(f"  ä¿å­˜ä½ç½®: {output_path2.absolute()}")

# æ€»ç»“
print("\n" + "=" * 70)
print("æµ‹è¯•å®Œæˆï¼")
print("=" * 70)
print(f"\nå¹³å‡é€Ÿåº¦: {(elapsed + elapsed2) / 2:.2f} ç§’/å¼ ")
print(f"æ˜¾å­˜å ç”¨: {memory:.2f} GB")

if (elapsed + elapsed2) / 2 < 30:
    print("\nğŸš€ é€Ÿåº¦ä¼˜ç§€ï¼")
else:
    print("\nâœ“ é€Ÿåº¦å¯æ¥å—")

print("\næç¤º:")
print("  - æ”¯æŒä¸­æ–‡æç¤ºè¯ï¼ˆç®€å•ç¿»è¯‘ï¼‰")
print("  - åç»­å¯æ¥å…¥Kimi APIå®ç°æ›´å¥½çš„ç¿»è¯‘")
print("  - ä½¿ç”¨è‹±æ–‡æç¤ºè¯æ•ˆæœæ›´å¥½")

print("\n" + "=" * 70)
