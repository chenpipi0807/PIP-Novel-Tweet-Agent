"""
Agent å·¥å…·ç®±
å°†åŸæœ‰åŠŸèƒ½å°è£…ä¸º Agent å¯è°ƒç”¨çš„å·¥å…·
"""
import json
from pathlib import Path
from typing import Dict, Any, Optional


class AgentTools:
    """Agent å·¥å…·é›†åˆ"""
    
    def __init__(self, video_generator):
        """
        åˆå§‹åŒ–å·¥å…·
        
        Args:
            video_generator: VideoGenerator å®ä¾‹
        """
        self.generator = video_generator
        self.llm_client = None  # å°†åœ¨åé¢è®¾ç½®
    
    def inspect_and_continue(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šæ£€æŸ¥é¡¹ç›®çŠ¶æ€å¹¶è‡ªåŠ¨ç»§ç»­ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰
        
        Returns:
            é¡¹ç›®çŠ¶æ€ + ä¸‹ä¸€æ­¥æ“ä½œ + è‡ªåŠ¨æ‰§è¡Œç»“æœ
        """
        print("ğŸ” æ­£åœ¨æ£€æŸ¥é¡¹ç›®çŠ¶æ€å¹¶è‡ªåŠ¨ç»§ç»­...")
        
        try:
            from project_inspector import ProjectInspector
            
            inspector = ProjectInspector(self.generator.project_name)
            report = inspector.inspect()
            report_text = inspector.generate_report_text()
            
            print(report_text)
            
            # æ ¹æ®æ£€æŸ¥ç»“æœè‡ªåŠ¨æ‰§è¡Œä¸‹ä¸€æ­¥
            next_action = report['next_action']
            
            result = {
                "status": "success",
                "report": report,
                "steps_completed": report['steps_completed'],
                "next_action": next_action,
                "current_step": report['current_step'],
                "issues": report['issues'],
                "message": f"é¡¹ç›®æ£€æŸ¥å®Œæˆï¼Œå·²å®Œæˆ{len(report['steps_completed'])}/4æ­¥"
            }
            
            # å¦‚æœæœ‰ä¸‹ä¸€æ­¥æ“ä½œï¼Œæç¤ºåº”è¯¥æ‰§è¡Œä»€ä¹ˆ
            if next_action and next_action != "ä»»åŠ¡å·²å®Œæˆ":
                action_map = {
                    "generate_audio": "generate_audio",
                    "generate_prompts": "generate_prompts",
                    "generate_images": "generate_images",
                    "continue_generate_images": "generate_images",
                    "generate_video": "compose_video"
                }
                suggested_tool = action_map.get(next_action, next_action)
                result["suggested_next_tool"] = suggested_tool
                result["message"] += f"ï¼Œå»ºè®®æ‰§è¡Œ: {suggested_tool}"
            
            return result
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"æ£€æŸ¥å¤±è´¥: {str(e)}"
            }
    
    def inspect_project(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šæ£€æŸ¥é¡¹ç›®çŠ¶æ€ï¼ˆä¼šæ›´æ–°Agentçš„å†…å­˜çŠ¶æ€ï¼‰
        
        Returns:
            é¡¹ç›®çŠ¶æ€æŠ¥å‘Š
        """
        print("ğŸ” æ­£åœ¨æ£€æŸ¥é¡¹ç›®çŠ¶æ€...")
        
        try:
            from project_inspector import ProjectInspector
            
            inspector = ProjectInspector(self.generator.project_name)
            report = inspector.inspect()
            report_text = inspector.generate_report_text()
            
            print(report_text)
            
            # å…³é”®ï¼šå°†æ£€æŸ¥ç»“æœåŒæ­¥åˆ°è¿”å›å€¼ä¸­ï¼Œè®©Agentèƒ½å¤Ÿæ›´æ–°å†…å­˜
            return {
                "status": "success",
                "report": report,
                "report_text": report_text,
                "steps_completed": report['steps_completed'],  # å·²å®Œæˆçš„æ­¥éª¤
                "next_action": report['next_action'],  # ä¸‹ä¸€æ­¥æ“ä½œ
                "current_step": report['current_step'],  # å½“å‰çŠ¶æ€
                "issues": report['issues'],  # é—®é¢˜åˆ—è¡¨
                "message": f"é¡¹ç›®æ£€æŸ¥å®Œæˆï¼Œå·²å®Œæˆ{len(report['steps_completed'])}/4æ­¥ï¼Œä¸‹ä¸€æ­¥: {report['next_action']}"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"é¡¹ç›®æ£€æŸ¥å¤±è´¥: {str(e)}"
            }
        
    def regenerate_scene(self, scene_number: int, new_prompt: str = None, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šé‡æ–°ç”ŸæˆæŒ‡å®šåœºæ™¯çš„å›¾åƒï¼ˆå®Œæ•´å®ç°ï¼‰
        
        Args:
            scene_number: åœºæ™¯ç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰
            new_prompt: æ–°çš„æç¤ºè¯ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨ç°æœ‰æç¤ºè¯ï¼‰
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print(f"ğŸ¨ æ­£åœ¨é‡æ–°ç”Ÿæˆåœºæ™¯ {scene_number}...")
        
        try:
            # è°ƒç”¨ç‹¬ç«‹çš„å•å›¾é‡ç”Ÿå·¥å…·
            from agent_tools_single_image import regenerate_single_image_tool
            
            result = regenerate_single_image_tool(
                project_name=self.generator.project_name,
                scene_index=scene_number,
                new_prompt=new_prompt
            )
            
            if result['success']:
                return {
                    "status": "success",
                    "scene_number": scene_number,
                    "message": result['message'],
                    "image_path": result.get('image_path'),
                    "prompt": result.get('prompt')
                }
            else:
                return {
                    "status": "error",
                    "message": result.get('error', 'æœªçŸ¥é”™è¯¯')
                }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def regenerate_scenes_batch(self, scene_numbers: list, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šæ‰¹é‡é‡æ–°ç”Ÿæˆå¤šä¸ªåœºæ™¯
        
        Args:
            scene_numbers: åœºæ™¯ç¼–å·åˆ—è¡¨
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print(f"ğŸ¨ æ­£åœ¨æ‰¹é‡é‡æ–°ç”Ÿæˆ {len(scene_numbers)} ä¸ªåœºæ™¯...")
        
        results = []
        for scene_num in scene_numbers:
            result = self.regenerate_scene(scene_num)
            results.append({
                "scene": scene_num,
                "status": result["status"]
            })
        
        success_count = sum(1 for r in results if r["status"] == "success")
        
        return {
            "status": "success" if success_count == len(scene_numbers) else "partial",
            "total": len(scene_numbers),
            "success": success_count,
            "failed": len(scene_numbers) - success_count,
            "message": f"æ‰¹é‡é‡æ–°ç”Ÿæˆå®Œæˆ: {success_count}/{len(scene_numbers)} æˆåŠŸ"
        }
    
    def refine_prompts(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šè‡ªåŠ¨ä¼˜åŒ–æ‰€æœ‰æç¤ºè¯ï¼ˆç²¾ç®€é•¿åº¦ã€æ£€æŸ¥è´¨é‡ï¼‰
        
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        print("âœ¨ æ­£åœ¨ä¼˜åŒ–æç¤ºè¯...")
        
        try:
            import json
            from pathlib import Path
            
            prompts_file = self.generator.project_dir / "Prompts.json"
            if not prompts_file.exists():
                return {
                    "status": "error",
                    "message": "æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            with open(prompts_file, 'r', encoding='utf-8') as f:
                prompts_data = json.load(f)
            
            scene_prompts = prompts_data.get('scene_prompts', [])
            optimized_count = 0
            issues_fixed = []
            
            for i, scene in enumerate(scene_prompts, 1):
                prompt = scene['prompt']
                original_length = len(prompt.split())
                
                # æ£€æŸ¥é•¿åº¦
                if original_length > 60:
                    # ç®€åŒ–æç¤ºè¯ï¼šç§»é™¤å†—ä½™è¯æ±‡
                    prompt = prompt.replace('masterpiece, best quality, highly detailed, anime', '')
                    prompt = prompt.replace('masterpiece, best quality, anime', '')
                    prompt = prompt.replace(', masterpiece, best quality', '')
                    prompt = prompt.replace('highly detailed, ', '')
                    prompt = prompt.replace(', highly detailed', '')
                    prompt = prompt.strip(', ')
                    
                    new_length = len(prompt.split())
                    if new_length < original_length:
                        scene['prompt'] = prompt
                        optimized_count += 1
                        issues_fixed.append(f"åœºæ™¯{i}: {original_length}è¯ â†’ {new_length}è¯")
            
            # ä¿å­˜ä¼˜åŒ–åçš„æç¤ºè¯
            if optimized_count > 0:
                with open(prompts_file, 'w', encoding='utf-8') as f:
                    json.dump(prompts_data, f, ensure_ascii=False, indent=2)
                
                print(f"âœ“ å·²ä¼˜åŒ– {optimized_count} ä¸ªæç¤ºè¯")
                for issue in issues_fixed:
                    print(f"  â€¢ {issue}")
            
            return {
                "status": "success",
                "optimized_count": optimized_count,
                "total_count": len(scene_prompts),
                "issues_fixed": issues_fixed,
                "message": f"æç¤ºè¯ä¼˜åŒ–å®Œæˆ: {optimized_count}/{len(scene_prompts)} ä¸ªéœ€è¦ä¼˜åŒ–"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"ä¼˜åŒ–å¤±è´¥: {str(e)}"
            }
    
    def validate_prompts(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šéªŒè¯æç¤ºè¯è´¨é‡
        
        Returns:
            éªŒè¯ç»“æœå’Œé—®é¢˜åˆ—è¡¨
        """
        print("ğŸ” æ­£åœ¨éªŒè¯æç¤ºè¯è´¨é‡...")
        
        try:
            import json
            
            prompts_file = self.generator.project_dir / "Prompts.json"
            if not prompts_file.exists():
                return {
                    "status": "error",
                    "message": "æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            with open(prompts_file, 'r', encoding='utf-8') as f:
                prompts_data = json.load(f)
            
            scene_prompts = prompts_data.get('scene_prompts', [])
            issues = []
            
            for i, scene in enumerate(scene_prompts, 1):
                prompt = scene['prompt']
                word_count = len(prompt.split())
                
                # æ£€æŸ¥é•¿åº¦
                if word_count > 60:
                    issues.append({
                        "scene": i,
                        "type": "too_long",
                        "message": f"åœºæ™¯{i}æç¤ºè¯è¿‡é•¿ï¼ˆ{word_count}è¯ï¼‰ï¼Œå»ºè®®â‰¤60è¯"
                    })
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è§’è‰²é€šé…ç¬¦
                if '{' not in prompt and '}' not in prompt:
                    issues.append({
                        "scene": i,
                        "type": "missing_character",
                        "message": f"åœºæ™¯{i}ç¼ºå°‘è§’è‰²é€šé…ç¬¦"
                    })
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åœºæ™¯
                if 'background' not in prompt.lower() and 'interior' not in prompt and 'street' not in prompt and 'battlefield' not in prompt:
                    issues.append({
                        "scene": i,
                        "type": "missing_scene",
                        "message": f"åœºæ™¯{i}å¯èƒ½ç¼ºå°‘åœºæ™¯æè¿°"
                    })
            
            return {
                "status": "success",
                "total_scenes": len(scene_prompts),
                "issues_count": len(issues),
                "issues": issues,
                "message": f"éªŒè¯å®Œæˆ: å‘ç° {len(issues)} ä¸ªé—®é¢˜"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"éªŒè¯å¤±è´¥: {str(e)}"
            }
    
    def check_image_quality(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šæ£€æŸ¥æ‰€æœ‰å›¾åƒè´¨é‡
        
        Returns:
            è´¨é‡æ£€æŸ¥ç»“æœå’Œé—®é¢˜å›¾åƒåˆ—è¡¨
        """
        print("ğŸ” æ­£åœ¨æ£€æŸ¥å›¾åƒè´¨é‡...")
        
        try:
            from pathlib import Path
            import json
            
            # æ£€æŸ¥å›¾åƒæ–‡ä»¶
            image_files = list(self.generator.imgs_dir.glob("scene_*.png"))
            
            # è·å–é¢„æœŸæ•°é‡
            prompts_file = self.generator.project_dir / "Prompts.json"
            expected_count = 0
            if prompts_file.exists():
                with open(prompts_file, 'r', encoding='utf-8') as f:
                    prompts_data = json.load(f)
                    expected_count = len(prompts_data.get('scene_prompts', []))
            
            issues = []
            
            # æ£€æŸ¥å®Œæ•´æ€§
            if len(image_files) < expected_count:
                missing = expected_count - len(image_files)
                issues.append({
                    "type": "incomplete",
                    "severity": "high",
                    "message": f"å›¾åƒä¸å®Œæ•´ï¼šç¼ºå°‘ {missing} å¼ å›¾åƒ"
                })
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå¤ªå°å¯èƒ½æ˜¯ç”Ÿæˆå¤±è´¥ï¼‰
            for img_file in image_files:
                size_kb = img_file.stat().st_size / 1024
                if size_kb < 100:  # å°äº100KBå¯èƒ½æœ‰é—®é¢˜
                    scene_num = int(img_file.stem.split('_')[1])
                    issues.append({
                        "type": "small_file",
                        "severity": "medium",
                        "scene": scene_num,
                        "message": f"åœºæ™¯{scene_num}æ–‡ä»¶è¿‡å°ï¼ˆ{size_kb:.1f}KBï¼‰ï¼Œå¯èƒ½ç”Ÿæˆå¤±è´¥"
                    })
            
            return {
                "status": "success",
                "total_images": len(image_files),
                "expected_images": expected_count,
                "issues_count": len(issues),
                "issues": issues,
                "message": f"è´¨é‡æ£€æŸ¥å®Œæˆ: å‘ç° {len(issues)} ä¸ªé—®é¢˜"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"æ£€æŸ¥å¤±è´¥: {str(e)}"
            }
    
    def auto_fix_issues(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šè‡ªåŠ¨ä¿®å¤æ£€æµ‹åˆ°çš„é—®é¢˜
        
        Returns:
            ä¿®å¤ç»“æœ
        """
        print("ğŸ”§ æ­£åœ¨è‡ªåŠ¨ä¿®å¤é—®é¢˜...")
        
        try:
            # å…ˆæ£€æŸ¥é—®é¢˜
            check_result = self.check_image_quality()
            
            if check_result["status"] != "success":
                return check_result
            
            issues = check_result.get("issues", [])
            if not issues:
                return {
                    "status": "success",
                    "message": "æ²¡æœ‰å‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜"
                }
            
            fixed_count = 0
            actions = []
            
            for issue in issues:
                if issue["type"] == "incomplete":
                    # å›¾åƒä¸å®Œæ•´ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ
                    actions.append("éœ€è¦æ‰§è¡Œ generate_images è¡¥å…¨å›¾åƒ")
                    fixed_count += 1
                    
                elif issue["type"] == "small_file":
                    # æ–‡ä»¶è¿‡å°ï¼Œåˆ é™¤å¹¶æ ‡è®°é‡æ–°ç”Ÿæˆ
                    scene_num = issue["scene"]
                    img_file = self.generator.imgs_dir / f"scene_{scene_num:04d}.png"
                    if img_file.exists():
                        img_file.unlink()
                        actions.append(f"å·²åˆ é™¤é—®é¢˜å›¾åƒ: åœºæ™¯{scene_num}")
                        fixed_count += 1
            
            return {
                "status": "success",
                "issues_found": len(issues),
                "fixed_count": fixed_count,
                "actions": actions,
                "message": f"è‡ªåŠ¨ä¿®å¤å®Œæˆ: {fixed_count}/{len(issues)} ä¸ªé—®é¢˜å·²å¤„ç†ï¼Œè¯·æ‰§è¡Œ generate_images é‡æ–°ç”Ÿæˆ"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"ä¿®å¤å¤±è´¥: {str(e)}"
            }
    
    def change_style(self, new_style_id: str, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šæ›´æ¢æ•´ä¸ªé¡¹ç›®çš„é£æ ¼
        
        Args:
            new_style_id: æ–°é£æ ¼ID
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print(f"ğŸ¨ æ­£åœ¨åˆ‡æ¢é£æ ¼åˆ°: {new_style_id}...")
        
        try:
            import json
            from sdxl.style_manager import StyleManager
            
            # æ£€æŸ¥é£æ ¼æ˜¯å¦å­˜åœ¨
            style_manager = StyleManager()
            if not style_manager.preset_exists(new_style_id):
                available = style_manager.list_presets(include_advanced=False)
                return {
                    "status": "error",
                    "message": f"é£æ ¼ä¸å­˜åœ¨: {new_style_id}",
                    "available_styles": [p['id'] for p in available]
                }
            
            # æ›´æ–°Prompts.jsonä¸­çš„é£æ ¼
            prompts_file = self.generator.project_dir / "Prompts.json"
            if not prompts_file.exists():
                return {
                    "status": "error",
                    "message": "æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”Ÿæˆæç¤ºè¯"
                }
            
            with open(prompts_file, 'r', encoding='utf-8') as f:
                prompts_data = json.load(f)
            
            # æ›´æ–°é£æ ¼
            if 'story_metadata' not in prompts_data:
                prompts_data['story_metadata'] = {}
            
            old_style = prompts_data['story_metadata'].get('style_preset', 'æ— ')
            prompts_data['story_metadata']['style_preset'] = new_style_id
            
            with open(prompts_file, 'w', encoding='utf-8') as f:
                json.dump(prompts_data, f, ensure_ascii=False, indent=2)
            
            # åˆ é™¤æ‰€æœ‰æ—§å›¾åƒ
            deleted_count = 0
            for img_file in self.generator.imgs_dir.glob("scene_*.png"):
                img_file.unlink()
                deleted_count += 1
            
            print(f"âœ“ é£æ ¼å·²åˆ‡æ¢: {old_style} â†’ {new_style_id}")
            print(f"âœ“ å·²åˆ é™¤ {deleted_count} å¼ æ—§å›¾åƒ")
            
            return {
                "status": "success",
                "old_style": old_style,
                "new_style": new_style_id,
                "deleted_images": deleted_count,
                "message": f"é£æ ¼å·²åˆ‡æ¢åˆ° {new_style_id}ï¼Œè¯·æ‰§è¡Œ generate_images é‡æ–°ç”Ÿæˆå›¾åƒ"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"åˆ‡æ¢å¤±è´¥: {str(e)}"
            }
    
    def set_llm_client(self, llm_client):
        """è®¾ç½® LLM å®¢æˆ·ç«¯"""
        self.llm_client = llm_client
    
    def generate_audio(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šç”ŸæˆéŸ³é¢‘å’Œå­—å¹•
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print("ğŸ™ï¸ æ­£åœ¨ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•...")
        
        try:
            success = self.generator.step1_generate_audio()
            
            if not success:
                return {
                    "status": "error",
                    "message": "éŸ³é¢‘ç”Ÿæˆå¤±è´¥"
                }
            
            # æ£€æŸ¥å­—å¹•æ–‡ä»¶ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
            subtitle_path = self.generator.project_dir / "Audio" / "Subtitles.json"
            if subtitle_path.exists():
                with open(subtitle_path, 'r', encoding='utf-8') as f:
                    subtitles = json.load(f)
                
                # æ–°æ ¼å¼ï¼šparent_scenes
                if 'parent_scenes' in subtitles:
                    parent_count = subtitles.get('total_parent_scenes', 0)
                    child_count = subtitles.get('total_child_scenes', 0)
                    
                    if parent_count == 0:
                        return {
                            "status": "error",
                            "message": "å­—å¹•ç”Ÿæˆå¤±è´¥ï¼šçˆ¶åˆ†é•œæ•°é‡ä¸º0"
                        }
                    
                    return {
                        "status": "success",
                        "parent_count": parent_count,
                        "child_count": child_count,
                        "message": f"æˆåŠŸç”Ÿæˆ {parent_count} ä¸ªçˆ¶åˆ†é•œï¼ˆå›¾ç‰‡ï¼‰ï¼Œ{child_count} ä¸ªå­åˆ†é•œï¼ˆå­—å¹•ï¼‰"
                    }
                else:
                    # æ—§æ ¼å¼ï¼šsubtitles
                    subtitle_count = len(subtitles.get("subtitles", []))
                    
                    if subtitle_count == 0:
                        return {
                            "status": "error",
                            "message": "å­—å¹•ç”Ÿæˆå¤±è´¥ï¼šå­—å¹•æ•°é‡ä¸º0"
                        }
                    
                    return {
                        "status": "success",
                        "subtitle_count": subtitle_count,
                        "message": f"æˆåŠŸç”Ÿæˆ {subtitle_count} æ¡å­—å¹•"
                    }
            else:
                return {
                    "status": "error",
                    "message": "å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def generate_prompts(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šç”Ÿæˆå›¾åƒæç¤ºè¯ï¼ˆAgentæ¨¡å¼ä¼šæ™ºèƒ½é€‰æ‹©é£æ ¼ï¼‰
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print("ğŸ“ æ­£åœ¨ç”Ÿæˆå›¾åƒæç¤ºè¯...")
        
        # Agentæ¨¡å¼ï¼šæ ‡è®°ä¸ºautoæ¨¡å¼ï¼Œè®©ç³»ç»Ÿæ™ºèƒ½é€‰æ‹©é£æ ¼
        kwargs['agent_mode'] = True
        
        try:
            success = self.generator.step2_generate_prompts(agent_mode=True)
            
            if not success:
                return {
                    "status": "error",
                    "message": "æç¤ºè¯ç”Ÿæˆå¤±è´¥"
                }
            
            # æ£€æŸ¥æç¤ºè¯æ–‡ä»¶
            prompts_path = self.generator.project_dir / "Prompts.json"
            if not prompts_path.exists():
                return {
                    "status": "error",
                    "message": "æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            with open(prompts_path, 'r', encoding='utf-8') as f:
                prompts_data = json.load(f)
            
            scene_count = len(prompts_data.get("scene_prompts", []))
            
            if scene_count == 0:
                return {
                    "status": "error",
                    "message": "æç¤ºè¯ç”Ÿæˆå¤±è´¥ï¼šåœºæ™¯æ•°é‡ä¸º0"
                }
            
            return {
                "status": "success",
                "scene_count": scene_count,
                "message": f"æˆåŠŸç”Ÿæˆ {scene_count} ä¸ªåˆ†é•œæç¤ºè¯"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"æç¤ºè¯ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def generate_images(self, sampling_steps: int = 16, cfg_scale: float = 2.5, 
                       sampler: str = "EulerA", **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šç”Ÿæˆå›¾åƒ
        
        Args:
            sampling_steps: é‡‡æ ·æ­¥æ•°
            cfg_scale: CFG Scale
            sampler: é‡‡æ ·å™¨
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾åƒ...")
        print(f"   å‚æ•°: steps={sampling_steps}, cfg={cfg_scale}, sampler={sampler}")
        
        try:
            success = self.generator.step3_generate_images()
            
            if not success:
                return {
                    "status": "error",
                    "message": "å›¾åƒç”Ÿæˆå¤±è´¥"
                }
            
            # ç»Ÿè®¡ç”Ÿæˆçš„å›¾åƒ
            imgs_dir = self.generator.project_dir / "Imgs"
            if not imgs_dir.exists():
                return {
                    "status": "error",
                    "message": "å›¾åƒç›®å½•ä¸å­˜åœ¨"
                }
            
            image_files = list(imgs_dir.glob("scene_*.png"))
            
            if len(image_files) == 0:
                return {
                    "status": "error",
                    "message": "å›¾åƒç”Ÿæˆå¤±è´¥ï¼šå›¾åƒæ•°é‡ä¸º0"
                }
            
            return {
                "status": "success",
                "image_count": len(image_files),
                "message": f"æˆåŠŸç”Ÿæˆ {len(image_files)} å¼ å›¾åƒ"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def compose_video(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šåˆæˆè§†é¢‘
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print("ğŸ¬ æ­£åœ¨åˆæˆè§†é¢‘...")
        
        try:
            success = self.generator.step4_compose_video()
            
            if not success:
                return {
                    "status": "error",
                    "message": "è§†é¢‘åˆæˆå¤±è´¥"
                }
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘
            videos_dir = self.generator.project_dir / "Videos"
            if not videos_dir.exists():
                return {
                    "status": "error",
                    "message": "è§†é¢‘ç›®å½•ä¸å­˜åœ¨"
                }
            
            video_files = list(videos_dir.glob("*.mp4"))
            if not video_files:
                return {
                    "status": "error",
                    "message": "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            video_path = str(video_files[0])
            
            return {
                "status": "success",
                "video_path": video_path,
                "message": f"è§†é¢‘åˆæˆå®Œæˆ: {video_path}"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"è§†é¢‘åˆæˆå¤±è´¥: {str(e)}"
            }
    
    def evaluate_quality(self, **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šè¯„ä¼°ç”Ÿæˆè´¨é‡
        
        ä½¿ç”¨ LLM è¯„ä¼°å½“å‰ç”Ÿæˆç»“æœçš„è´¨é‡
        
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        print("ğŸ” æ­£åœ¨è¯„ä¼°è´¨é‡...")
        
        try:
            # æ”¶é›†å½“å‰çŠ¶æ€ä¿¡æ¯
            project_dir = self.generator.project_dir
            
            # æ£€æŸ¥å„ä¸ªæ­¥éª¤çš„å®Œæˆæƒ…å†µ
            has_audio = (project_dir / "Audio" / "audio.mp3").exists()
            has_subtitles = (project_dir / "Audio" / "Subtitles.json").exists()
            has_prompts = (project_dir / "Prompts.json").exists()
            
            imgs_dir = project_dir / "Imgs"
            image_count = len(list(imgs_dir.glob("scene_*.png"))) if imgs_dir.exists() else 0
            
            videos_dir = project_dir / "Videos"
            has_video = len(list(videos_dir.glob("*.mp4"))) > 0 if videos_dir.exists() else False
            
            # è¯»å–å­—å¹•æ•°é‡
            subtitle_count = 0
            if has_subtitles:
                with open(project_dir / "Audio" / "Subtitles.json", 'r', encoding='utf-8') as f:
                    subtitles = json.load(f)
                    subtitle_count = len(subtitles)
            
            # è¯»å–åœºæ™¯æ•°é‡
            scene_count = 0
            if has_prompts:
                with open(project_dir / "Prompts.json", 'r', encoding='utf-8') as f:
                    prompts_data = json.load(f)
                    scene_count = len(prompts_data.get("scene_prompts", []))
            
            # ä½¿ç”¨ LLM è¯„ä¼°è´¨é‡
            if self.llm_client:
                evaluation = self._llm_evaluate_quality(
                    has_audio, has_subtitles, has_prompts, 
                    image_count, scene_count, subtitle_count, has_video
                )
            else:
                # ç®€å•è¯„ä¼°ï¼ˆæ—  LLMï¼‰
                evaluation = self._simple_evaluate_quality(
                    has_audio, has_subtitles, has_prompts,
                    image_count, scene_count, subtitle_count, has_video
                )
            
            print(f"   æ€»ä½“è´¨é‡: {evaluation['overall_score']:.2f}")
            print(f"   å®Œæ•´æ€§: {evaluation['completeness']:.2f}")
            
            return evaluation
            
        except Exception as e:
            print(f"âš ï¸ è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return {
                "status": "error",
                "overall_score": 0.5,
                "completeness": 0.5,
                "issues": [f"è¯„ä¼°å¤±è´¥: {str(e)}"],
                "suggestions": ["è¯·æ£€æŸ¥ç”Ÿæˆæµç¨‹"]
            }
    
    def _llm_evaluate_quality(self, has_audio, has_subtitles, has_prompts,
                             image_count, scene_count, subtitle_count, has_video) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM è¯„ä¼°è´¨é‡"""
        
        prompt = f"""è¯·è¯„ä¼°å›¾åƒç”Ÿæˆè´¨é‡ï¼ˆ0-1åˆ†ï¼‰ï¼š

**åªå…³æ³¨å›¾åƒè´¨é‡ï¼Œä¸è¯„ä¼°éŸ³é¢‘ï¼**

å½“å‰çŠ¶æ€ï¼š
- æç¤ºè¯æ–‡ä»¶: {"âœ“" if has_prompts else "âœ—"} ({scene_count} ä¸ªåœºæ™¯)
- ç”Ÿæˆå›¾åƒ: {image_count} å¼  (é¢„æœŸ {scene_count} å¼ )
- æœ€ç»ˆè§†é¢‘: {"âœ“" if has_video else "âœ—"}

è¯„ä¼°æ ‡å‡†ï¼ˆåªçœ‹å›¾åƒï¼‰ï¼š
1. å›¾åƒå®Œæ•´æ€§ (0-1): å›¾åƒæ•°é‡æ˜¯å¦åŒ¹é…åœºæ™¯æ•°é‡
2. å›¾åƒä¸€è‡´æ€§ (0-1): å›¾åƒé£æ ¼æ˜¯å¦ç»Ÿä¸€
3. å†…å®¹åŒ¹é…åº¦ (0-1): å›¾åƒå†…å®¹æ˜¯å¦åŒ¹é…å¯¹åº”çš„å­—å¹•å’Œæç¤ºè¯

è¯·ä»¥JSONæ ¼å¼å›ç­”ï¼ˆåªè¿”å›JSONï¼‰ï¼š
{{
    "overall_score": 0.85,
    "completeness": 1.0,
    "consistency": 0.9,
    "quality": 0.8,
    "issues": ["é—®é¢˜æè¿°"],
    "suggestions": ["æ”¹è¿›å»ºè®®"]
}}"""

        try:
            messages = [{"role": "user", "content": prompt}]
            response = self.llm_client.chat(messages)
            
            if not response:
                raise Exception("LLMè¿”å›ä¸ºç©º")
            
            # æå–JSON
            response = response.strip()
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                response = response.split("```")[1].split("```")[0].strip()
            
            evaluation = json.loads(response)
            return evaluation
            
        except Exception as e:
            print(f"âš ï¸ LLMè¯„ä¼°å¤±è´¥: {e}")
            # é™çº§åˆ°ç®€å•è¯„ä¼°
            return self._simple_evaluate_quality(
                has_audio, has_subtitles, has_prompts,
                image_count, scene_count, subtitle_count, has_video
            )
    
    def _simple_evaluate_quality(self, has_audio, has_subtitles, has_prompts,
                                 image_count, scene_count, subtitle_count, has_video) -> Dict[str, Any]:
        """ç®€å•è´¨é‡è¯„ä¼°ï¼ˆä¸ä½¿ç”¨ LLMï¼‰- åªå…³æ³¨å›¾åƒè´¨é‡"""
        
        # è®¡ç®—å®Œæ•´æ€§ï¼ˆåªçœ‹å…³é”®æ­¥éª¤ï¼‰
        completeness_score = 0.0
        if has_prompts:
            completeness_score += 0.25
        if image_count > 0:
            completeness_score += 0.5  # å›¾åƒæœ€é‡è¦
        if has_video:
            completeness_score += 0.25
        
        # è®¡ç®—ä¸€è‡´æ€§ï¼ˆå›¾åƒæ•°é‡æ˜¯å¦åŒ¹é…åœºæ™¯ï¼‰
        consistency_score = 1.0
        if scene_count > 0 and image_count != scene_count:
            consistency_score = image_count / scene_count if image_count < scene_count else scene_count / image_count
        
        # æ€»ä½“åˆ†æ•° - é‡ç‚¹å…³æ³¨å›¾åƒ
        overall_score = (completeness_score * 0.5 + consistency_score * 0.5)
        
        # å‘ç°çš„é—®é¢˜ - åªå…³æ³¨å›¾åƒç›¸å…³
        issues = []
        if not has_prompts:
            issues.append("ç¼ºå°‘æç¤ºè¯æ–‡ä»¶")
        if image_count == 0:
            issues.append("æœªç”Ÿæˆå›¾åƒ")
        elif image_count != scene_count:
            issues.append(f"å›¾åƒæ•°é‡({image_count})ä¸åœºæ™¯æ•°é‡({scene_count})ä¸åŒ¹é…")
        if not has_video:
            issues.append("æœªç”Ÿæˆæœ€ç»ˆè§†é¢‘")
        
        # æ”¹è¿›å»ºè®®
        suggestions = []
        if image_count == 0:
            suggestions.append("éœ€è¦ç”Ÿæˆå›¾åƒ")
        elif image_count != scene_count:
            suggestions.append("éœ€è¦è¡¥å……ç¼ºå¤±çš„å›¾åƒ")
        elif overall_score < 0.8:
            suggestions.append("å»ºè®®æ£€æŸ¥å›¾åƒè´¨é‡")
        else:
            suggestions.append("å›¾åƒç”Ÿæˆå®Œæ•´ï¼Œè´¨é‡è‰¯å¥½")
        
        return {
            "overall_score": overall_score,
            "completeness": completeness_score,
            "consistency": consistency_score,
            "quality": overall_score,
            "issues": issues,
            "suggestions": suggestions
        }
    
    def adjust_parameters(self, evaluation: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """
        å·¥å…·ï¼šæ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´å‚æ•°
        
        Args:
            evaluation: è´¨é‡è¯„ä¼°ç»“æœ
            
        Returns:
            æ–°çš„å‚æ•°é…ç½®
        """
        print("âš™ï¸ æ­£åœ¨è°ƒæ•´å‚æ•°...")
        
        try:
            overall_score = evaluation.get("overall_score", 0.5)
            
            # ä½¿ç”¨ LLM å†³å®šå‚æ•°è°ƒæ•´
            if self.llm_client:
                new_params = self._llm_adjust_parameters(evaluation)
            else:
                # ç®€å•è§„åˆ™è°ƒæ•´
                new_params = self._simple_adjust_parameters(overall_score)
            
            print(f"   æ–°å‚æ•°: {json.dumps(new_params, ensure_ascii=False)}")
            
            return new_params
            
        except Exception as e:
            print(f"âš ï¸ å‚æ•°è°ƒæ•´å¤±è´¥: {e}")
            return {
                "sampling_steps": 16,
                "cfg_scale": 2.5,
                "sampler": "EulerA"
            }
    
    def _llm_adjust_parameters(self, evaluation: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM è°ƒæ•´å‚æ•°"""
        
        prompt = f"""æ ¹æ®è´¨é‡è¯„ä¼°ç»“æœï¼Œå»ºè®®è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼š

è¯„ä¼°ç»“æœï¼š
{json.dumps(evaluation, ensure_ascii=False, indent=2)}

å½“å‰å‚æ•°ï¼š
- é‡‡æ ·æ­¥æ•°: 12
- CFG Scale: 2.5
- é‡‡æ ·å™¨: EulerA

å‚æ•°èŒƒå›´ï¼š
- é‡‡æ ·æ­¥æ•°: 4-16
- CFG Scale: 1.5-4.0
- é‡‡æ ·å™¨: EulerA, DPM++SDE, DDIM

è¯·å»ºè®®æ–°çš„å‚æ•°é…ç½®ã€‚ä»¥JSONæ ¼å¼å›ç­”ï¼ˆåªè¿”å›JSONï¼‰ï¼š
{{
    "sampling_steps": 16,
    "cfg_scale": 3.0,
    "sampler": "EulerA",
    "reason": "è°ƒæ•´åŸå› "
}}"""

        try:
            messages = [{"role": "user", "content": prompt}]
            response = self.llm_client.chat(messages)
            
            if not response:
                raise Exception("LLMè¿”å›ä¸ºç©º")
            
            # æå–JSON
            response = response.strip()
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                response = response.split("```")[1].split("```")[0].strip()
            
            new_params = json.loads(response)
            return new_params
            
        except Exception as e:
            print(f"âš ï¸ LLMå‚æ•°è°ƒæ•´å¤±è´¥: {e}")
            return self._simple_adjust_parameters(evaluation.get("overall_score", 0.5))
    
    def _simple_adjust_parameters(self, overall_score: float) -> Dict[str, Any]:
        """ç®€å•å‚æ•°è°ƒæ•´è§„åˆ™"""
        
        if overall_score < 0.5:
            # è´¨é‡å¾ˆå·®ï¼Œå¤§å¹…è°ƒæ•´
            return {
                "sampling_steps": 16,
                "cfg_scale": 3.5,
                "sampler": "EulerA",
                "reason": "è´¨é‡è¿‡ä½ï¼Œå¢åŠ é‡‡æ ·æ­¥æ•°å’ŒCFG"
            }
        elif overall_score < 0.7:
            # è´¨é‡ä¸€èˆ¬ï¼Œå¾®è°ƒ
            return {
                "sampling_steps": 14,
                "cfg_scale": 3.0,
                "sampler": "EulerA",
                "reason": "è´¨é‡ä¸€èˆ¬ï¼Œé€‚åº¦æå‡å‚æ•°"
            }
        else:
            # è´¨é‡è‰¯å¥½ï¼Œä¿æŒ
            return {
                "sampling_steps": 16,
                "cfg_scale": 2.5,
                "sampler": "EulerA",
                "reason": "è´¨é‡è‰¯å¥½ï¼Œä¿æŒå½“å‰å‚æ•°"
            }
    
    def get_all_tools(self) -> Dict[str, callable]:
        """è·å–æ‰€æœ‰å·¥å…·çš„å­—å…¸"""
        return {
            # æ ¸å¿ƒå·¥ä½œæµå·¥å…·
            "inspect_and_continue": self.inspect_and_continue,  # ğŸ†• æ£€æŸ¥å¹¶ç»§ç»­ï¼ˆæ¨èï¼‰
            "inspect_project": self.inspect_project,  # é¡¹ç›®çŠ¶æ€æ£€æŸ¥
            "generate_audio": self.generate_audio,
            "generate_prompts": self.generate_prompts,
            "generate_images": self.generate_images,
            "compose_video": self.compose_video,
            "evaluate_quality": self.evaluate_quality,
            
            # å›¾åƒå¤„ç†å·¥å…·
            "regenerate_scene": self.regenerate_scene,  # ğŸ†• é‡æ–°ç”Ÿæˆå•ä¸ªåœºæ™¯
            "regenerate_scenes_batch": self.regenerate_scenes_batch,  # ğŸ†• æ‰¹é‡é‡æ–°ç”Ÿæˆ
            
            # æç¤ºè¯å¤„ç†å·¥å…·
            "refine_prompts": self.refine_prompts,  # ğŸ†• è‡ªåŠ¨ä¼˜åŒ–æç¤ºè¯
            "validate_prompts": self.validate_prompts,  # ğŸ†• éªŒè¯æç¤ºè¯è´¨é‡
            
            # è´¨é‡æ§åˆ¶å·¥å…·
            "check_image_quality": self.check_image_quality,  # ğŸ†• æ£€æŸ¥å›¾åƒè´¨é‡
            "auto_fix_issues": self.auto_fix_issues,  # ğŸ†• è‡ªåŠ¨ä¿®å¤é—®é¢˜
            
            # é£æ ¼ç®¡ç†å·¥å…·
            "change_style": self.change_style,  # ğŸ†• åˆ‡æ¢é£æ ¼
            
            # å‚æ•°è°ƒæ•´å·¥å…·
            "adjust_parameters": self.adjust_parameters
        }
