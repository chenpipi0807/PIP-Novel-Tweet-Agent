"""
Agentå·¥å…·ï¼šå•å¼ å›¾ç‰‡é‡æ–°ç”Ÿæˆ
"""
from pathlib import Path
import json


def regenerate_single_image_tool(project_name: str, scene_index: int, new_prompt: str = None):
    """
    é‡æ–°ç”Ÿæˆå•å¼ åˆ†é•œå›¾ç‰‡
    
    Args:
        project_name: é¡¹ç›®åç§°
        scene_index: åœºæ™¯ç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰
        new_prompt: æ–°çš„æç¤ºè¯ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨ç°æœ‰æç¤ºè¯ï¼‰
    
    Returns:
        dict: æ‰§è¡Œç»“æœ
    """
    try:
        from main import VideoGenerator
        import torch
        import gc
        
        print(f"\nğŸ¨ å•å›¾é‡ç”Ÿå·¥å…·: scene_{scene_index:04d}")
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        generator = VideoGenerator(project_name, "")
        
        # è¯»å–æç¤ºè¯
        prompts_file = generator.project_dir / 'Prompts.json'
        if not prompts_file.exists():
            return {
                "success": False,
                "error": "æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨"
            }
        
        with open(prompts_file, 'r', encoding='utf-8') as f:
            prompts_data = json.load(f)
        
        # å¦‚æœæä¾›äº†æ–°æç¤ºè¯ï¼Œæ›´æ–°å®ƒ
        if new_prompt:
            updated = False
            for scene in prompts_data.get('scene_prompts', []):
                if scene['index'] == scene_index:
                    scene['prompt'] = new_prompt
                    updated = True
                    break
            
            if updated:
                with open(prompts_file, 'w', encoding='utf-8') as f:
                    json.dump(prompts_data, f, ensure_ascii=False, indent=2)
                print(f"âœ“ æç¤ºè¯å·²æ›´æ–°")
        
        # æ‰¾åˆ°å¯¹åº”çš„æç¤ºè¯
        scene_prompt = None
        for scene in prompts_data.get('scene_prompts', []):
            if scene['index'] == scene_index:
                scene_prompt = scene['prompt']
                break
        
        if not scene_prompt:
            return {
                "success": False,
                "error": f"æ‰¾ä¸åˆ°åœºæ™¯ {scene_index} çš„æç¤ºè¯"
            }
        
        print(f"æç¤ºè¯: {scene_prompt[:80]}...")
        
        # åŠ è½½SDXLæ¨¡å‹ï¼ˆä½¿ç”¨ä¸main.pyå®Œå…¨ç›¸åŒçš„é…ç½®ï¼‰
        from diffusers import StableDiffusionXLPipeline, EulerAncestralDiscreteScheduler
        
        # ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹è·¯å¾„
        model_dir = Path("sdxl/models/prefectIllustriousXL_40")
        model_path_file = model_dir / "prefectIllustriousXL_40.safetensors"
        
        if not model_path_file.exists():
            return {
                "success": False,
                "error": f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path_file}"
            }
        
        print("åŠ è½½SDXLæ¨¡å‹...")
        print(f"âœ“ ä½¿ç”¨æ¨¡å‹: Prefect Illustrious XL 40")
        
        pipe = StableDiffusionXLPipeline.from_single_file(
            str(model_path_file),
            torch_dtype=torch.float16,
            config=str(model_dir),
            local_files_only=True
        ).to("cuda")
        
        # åŠ è½½DMD2 LoRA
        dmd2_lora_path = Path("sdxl/models/loras/dmd2_sdxl_4step_lora.safetensors")
        if dmd2_lora_path.exists():
            pipe.load_lora_weights(
                str(dmd2_lora_path.parent),
                weight_name=dmd2_lora_path.name,
                adapter_name="dmd2"
            )
            pipe.set_adapters(["dmd2"], adapter_weights=[0.8])
            print("âœ“ DMD2 LoRAå·²åŠ è½½")
        
        # ä½¿ç”¨Euler Ancestralè°ƒåº¦å™¨
        pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(
            pipe.scheduler.config
        )
        
        pipe.enable_attention_slicing()
        pipe.enable_vae_slicing()
        
        # ç”Ÿæˆå›¾åƒï¼ˆä½¿ç”¨ä¸main.pyå®Œå…¨ç›¸åŒçš„å‚æ•°ï¼‰
        print("ç”Ÿæˆå›¾åƒ...")
        torch.cuda.empty_cache()
        import random
        seed = random.randint(0, 2**32 - 1)
        generator_obj = torch.Generator(device="cuda").manual_seed(seed)
        
        # è´Ÿé¢è¯ï¼ˆIllustriousä¸“ç”¨ - æ›´å…¨é¢çš„è´¨é‡æ§åˆ¶ï¼‰
        negative_prompt = "lazyneg, lazyhand, child, (censored, mosaic censoring, bar_censor), lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature"
        
        # æ·»åŠ è´¨é‡æ ‡ç­¾åˆ°æç¤ºè¯ï¼ˆIllustriousä¸“ç”¨PEæ ¼å¼ï¼‰
        quality_tags = "score_9, score_8_up, score_7_up, masterpiece, best quality, amazing quality, absurdres, newest"
        enhanced_prompt = f"{quality_tags}, BREAK {scene_prompt}"
        
        # ä½¿ç”¨DMD2åŠ é€Ÿæ¨¡å¼
        use_dmd2 = dmd2_lora_path.exists()
        if use_dmd2:
            # DMD2: 12æ­¥ï¼ŒCFG=2.5ï¼ˆåŸå§‹ç¨³å®šé…ç½®ï¼‰
            image = pipe(
                prompt=enhanced_prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=12,
                guidance_scale=2.5,
                width=1024,
                height=1024,
                generator=generator_obj,
                clip_skip=2
            ).images[0]
        else:
            # æ ‡å‡†æ¨¡å¼: 20æ­¥ï¼ŒCFG=7.0ï¼ˆåŸå§‹é…ç½®ï¼‰
            image = pipe(
                prompt=enhanced_prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=20,
                guidance_scale=7.0,
                width=1024,
                height=1024,
                generator=generator_obj,
                clip_skip=2
            ).images[0]
        
        # ä¿å­˜å›¾åƒ
        img_path = generator.imgs_dir / f"scene_{scene_index:04d}.png"
        image.save(img_path)
        print(f"âœ“ å›¾åƒå·²ä¿å­˜: {img_path}")
        
        # é‡Šæ”¾æ˜¾å­˜
        del pipe
        torch.cuda.empty_cache()
        gc.collect()
        
        return {
            "success": True,
            "message": f"åœºæ™¯ {scene_index} å·²é‡æ–°ç”Ÿæˆ",
            "image_path": str(img_path),
            "prompt": scene_prompt
        }
        
    except Exception as e:
        print(f"âŒ å•å›¾é‡ç”Ÿå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e)
        }
